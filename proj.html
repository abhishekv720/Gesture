<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Gesture Controlled 3D Particles</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #050505; font-family: sans-serif; }
        #canvas-container { width: 100vw; height: 100vh; }
        #video-input { position: absolute; top: 0; left: 0; opacity: 0; pointer-events: none; }
        #loading {
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            color: #00ff88; font-size: 1.5rem; pointer-events: none; text-align: center;
        }
        #ui-layer {
            position: absolute; bottom: 20px; left: 20px; color: white;
            pointer-events: none; background: rgba(0,0,0,0.5); padding: 15px; border-radius: 8px;
        }
        h1 { margin: 0 0 10px 0; font-size: 1.2rem; color: #00ff88; }
        p { margin: 5px 0; font-size: 0.9rem; }
        .data { font-weight: bold; color: #ff0055; }
    </style>
</head>
<body>

<div id="loading">Initializing Camera & AI...<br>Please allow camera access.</div>

<div id="ui-layer">
    <h1>Hand Control</h1>
    <p>üñê <b>Move X:</b> Morph Shape (Heart / Saturn / Flower)</p>
    <p>ü§è <b>Pinch:</b> Shift Color</p>
    <p>‚ÜïÔ∏è <b>Move Y/Z:</b> Expand Particles</p>
    <p>Active Shape: <span id="shape-name" class="data">Loading...</span></p>
</div>

<video id="video-input" autoplay playsinline></video>
<div id="canvas-container"></div>

<script type="module">
import * as THREE from 'https://unpkg.com/three@0.160.0/build/three.module.js';
import { FilesetResolver, HandLandmarker } from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/+esm';

// --- CONFIGURATION ---
const PARTICLE_COUNT = 15000;
const CANVAS_CONTAINER = document.getElementById('canvas-container');
const SHAPE_NAME_EL = document.getElementById('shape-name');

// --- THREE.JS SETUP ---
const scene = new THREE.Scene();
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.z = 30;

const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
renderer.setSize(window.innerWidth, window.innerHeight);
renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
CANVAS_CONTAINER.appendChild(renderer.domElement);

// --- PARTICLE SYSTEM ---
// We use a custom shader to handle morphing on the GPU for performance
const geometry = new THREE.BufferGeometry();
const positions = new Float32Array(PARTICLE_COUNT * 3);
const targets = new Float32Array(PARTICLE_COUNT * 3); // Target positions for morphing
const colors = new Float32Array(PARTICLE_COUNT * 3);
const sizes = new Float32Array(PARTICLE_COUNT);

// Initialize with random positions
for (let i = 0; i < PARTICLE_COUNT; i++) {
    positions[i * 3] = (Math.random() - 0.5) * 50;
    positions[i * 3 + 1] = (Math.random() - 0.5) * 50;
    positions[i * 3 + 2] = (Math.random() - 0.5) * 50;
    sizes[i] = Math.random();
}

geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
geometry.setAttribute('targetPosition', new THREE.BufferAttribute(targets, 3)); // Custom attribute
geometry.setAttribute('customColor', new THREE.BufferAttribute(colors, 3));
geometry.setAttribute('size', new THREE.BufferAttribute(sizes, 1));

// Custom Shader Material
const material = new THREE.ShaderMaterial({
    uniforms: {
        uTime: { value: 0 },
        uMixRatio: { value: 0 }, // 0 = current, 1 = target
        uColorHue: { value: 0.0 },
        uExpansion: { value: 1.0 },
        pointTexture: { value: new THREE.TextureLoader().load('https://assets.codepen.io/127738/dotTexture.png') }
    },
    vertexShader: `
        uniform float uTime;
        uniform float uMixRatio;
        uniform float uExpansion;
        uniform float uColorHue;
        
        attribute vec3 targetPosition;
        attribute float size;
        attribute vec3 customColor;
        
        varying vec3 vColor;

        // Function to convert Hue to RGB
        vec3 hueToRgb(float hue) {
            vec3 K = vec3(1.0, 2.0 / 3.0, 1.0 / 3.0);
            vec3 p = abs(fract(hue + K) * 6.0 - 3.0);
            return mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), 1.0);
        }

        void main() {
            // Morph between current position (attribute position) and target
            vec3 mixedPosition = mix(position, targetPosition, uMixRatio);
            
            // Add some noise/movement
            mixedPosition.x += sin(uTime * 2.0 + mixedPosition.y) * 0.2;
            mixedPosition.y += cos(uTime * 1.5 + mixedPosition.x) * 0.2;
            
            // Expansion logic
            mixedPosition *= uExpansion;

            vec4 mvPosition = modelViewMatrix * vec4(mixedPosition, 1.0);
            gl_Position = projectionMatrix * mvPosition;

            // Size attenuation
            gl_PointSize = size * (300.0 / -mvPosition.z);

            // Dynamic color based on position and hand pinch (hue)
            vec3 baseColor = hueToRgb(uColorHue + (mixedPosition.y * 0.05));
            vColor = baseColor;
        }
    `,
    fragmentShader: `
        uniform sampler2D pointTexture;
        varying vec3 vColor;
        void main() {
            gl_FragColor = vec4(vColor, 1.0);
            gl_FragColor = gl_FragColor * texture2D(pointTexture, gl_PointCoord);
            if (gl_FragColor.a < 0.1) discard;
        }
    `,
    transparent: true,
    depthWrite: false,
    blending: THREE.AdditiveBlending
});

const particles = new THREE.Points(geometry, material);
scene.add(particles);

// --- SHAPE GENERATORS ---
// Algorithms to fill the 'targets' array with specific shapes
const shapes = {
    heart: () => {
        const arr = [];
        for (let i = 0; i < PARTICLE_COUNT; i++) {
            // Heart formula
            let t = Math.random() * Math.PI * 2;
            let x = 16 * Math.pow(Math.sin(t), 3);
            let y = 13 * Math.cos(t) - 5 * Math.cos(2*t) - 2 * Math.cos(3*t) - Math.cos(4*t);
            let z = (Math.random() - 0.5) * 5; // Thickness
            arr.push(x, y, z);
        }
        return arr;
    },
    saturn: () => {
        const arr = [];
        for (let i = 0; i < PARTICLE_COUNT; i++) {
            // 70% Planet, 30% Rings
            if (i < PARTICLE_COUNT * 0.7) {
                const r = 10;
                const theta = Math.random() * Math.PI * 2;
                const phi = Math.acos(2 * Math.random() - 1);
                arr.push(
                    r * Math.sin(phi) * Math.cos(theta),
                    r * Math.sin(phi) * Math.sin(theta),
                    r * Math.cos(phi)
                );
            } else {
                const r = 14 + Math.random() * 8; // Ring radius
                const theta = Math.random() * Math.PI * 2;
                arr.push(
                    r * Math.cos(theta),
                    (Math.random()-0.5), // Flat ring
                    r * Math.sin(theta)
                );
            }
        }
        return arr;
    },
    flower: () => {
        const arr = [];
        for (let i = 0; i < PARTICLE_COUNT; i++) {
            const k = 4; // Petals
            const theta = Math.random() * Math.PI * 2;
            const r = 15 * Math.cos(k * theta); 
            // Add some 3D depth to petals
            const z = (Math.random() - 0.5) * 5;
            arr.push(r * Math.cos(theta), r * Math.sin(theta), z);
        }
        return arr;
    },
    sphere: () => { // "Fireworks" / Chaos state
        const arr = [];
        for (let i = 0; i < PARTICLE_COUNT; i++) {
             const r = 25 * Math.cbrt(Math.random()); 
             const theta = Math.random() * 2 * Math.PI;
             const phi = Math.acos(2 * Math.random() - 1);
             arr.push(
                r * Math.sin(phi) * Math.cos(theta),
                r * Math.sin(phi) * Math.sin(theta),
                r * Math.cos(phi)
             );
        }
        return arr;
    }
};

// State Management
let currentShape = 'sphere';
let targetShape = 'heart';
const shapeKeys = ['heart', 'saturn', 'flower', 'sphere'];
let morphAlpha = 0;

// Helper to update geometry targets
function setTargetShape(shapeKey) {
    if(currentShape === shapeKey) return;
    
    SHAPE_NAME_EL.innerText = shapeKey.toUpperCase();
    SHAPE_NAME_EL.style.color = '#00ff88';

    // Copy current positions to 'position' attribute to start morph from where we are
    // But since we use a mix shader, we essentially swap buffers. 
    // Simplified strategy: We just update the 'targetPosition' buffer.
    const newTargets = shapes[shapeKey]();
    const targetAttr = geometry.attributes.targetPosition;
    
    for(let i=0; i < newTargets.length; i++) {
        targetAttr.array[i] = newTargets[i];
    }
    targetAttr.needsUpdate = true;
    
    // Reset morph mix
    material.uniforms.uMixRatio.value = 0; 
    currentShape = shapeKey;
    morphAlpha = 0;
}

// Initial set
setTargetShape('heart');

// --- MEDIAPIPE HAND TRACKING ---
const video = document.getElementById('video-input');
let handLandmarker;
let lastVideoTime = -1;

async function setupMediaPipe() {
    const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
    );
    
    handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
            delegate: "GPU"
        },
        runningMode: "VIDEO",
        numHands: 1
    });

    // Start Webcam
    navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
        video.srcObject = stream;
        video.addEventListener("loadeddata", predictWebcam);
        document.getElementById('loading').style.display = 'none';
    });
}

function predictWebcam() {
    // Resize canvas if window changes
    if (video.videoWidth > 0 && video.videoHeight > 0) {
        let nowInMs = Date.now();
        if (lastVideoTime !== video.currentTime) {
            lastVideoTime = video.currentTime;
            
            const results = handLandmarker.detectForVideo(video, nowInMs);
            
            if (results.landmarks && results.landmarks.length > 0) {
                const hand = results.landmarks[0];
                
                // 1. Get Index Finger Tip (8) and Thumb Tip (4)
                const indexTip = hand[8];
                const thumbTip = hand[4];
                const wrist = hand[0];

                // Calculate pinch distance (Color Control)
                const distance = Math.hypot(
                    indexTip.x - thumbTip.x, 
                    indexTip.y - thumbTip.y
                );
                
                // Map pinch to Hue (0.0 - 1.0)
                // Pinch closed (small dist) -> specific color, Open -> changes
                const targetHue = THREE.MathUtils.mapLinear(distance, 0.02, 0.2, 0.0, 1.0);
                material.uniforms.uColorHue.value = THREE.MathUtils.lerp(material.uniforms.uColorHue.value, targetHue, 0.1);

                // 2. Hand X Position -> Shape Switching
                // x is 0 (left) to 1 (right) in MediaPipe
                // Let's divide screen into 3 zones
                const xPos = 1.0 - wrist.x; // Mirror effect
                
                if (xPos < 0.33) setTargetShape('heart');
                else if (xPos < 0.66) setTargetShape('saturn');
                else setTargetShape('flower');

                // 3. Hand Y/Z Position -> Expansion
                // y is 0 (top) to 1 (bottom)
                const yPos = 1.0 - wrist.y;
                const expansion = THREE.MathUtils.mapLinear(yPos, 0, 1, 0.5, 3.0);
                material.uniforms.uExpansion.value = THREE.MathUtils.lerp(material.uniforms.uExpansion.value, expansion, 0.1);
            }
        }
    }
    
    // Animation Loop request inside here to sync with video frame? 
    // Better to keep separate, but we call predict repeatedly
    window.requestAnimationFrame(predictWebcam);
}

// --- MAIN ANIMATION LOOP ---
const clock = new THREE.Clock();

function animate() {
    requestAnimationFrame(animate);
    
    const delta = clock.getDelta();
    material.uniforms.uTime.value += delta;
    
    // Smoothly interpolate the mix ratio to 1.0
    if (material.uniforms.uMixRatio.value < 1.0) {
        material.uniforms.uMixRatio.value += delta * 1.5; // Morph speed
    }

    // Gentle rotation of the whole system
    particles.rotation.y += delta * 0.1;
    particles.rotation.z += delta * 0.05;

    renderer.render(scene, camera);
}

// Init
setupMediaPipe();
animate();

// Handle Resize
window.addEventListener('resize', () => {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
});

</script>
</body>
</html>